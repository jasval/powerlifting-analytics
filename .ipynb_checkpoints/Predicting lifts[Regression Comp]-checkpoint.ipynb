{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampling 20,000 data entries\n",
    "# n = 767672 \n",
    "# s = 40000\n",
    "# skip = sorted(random.sample(range(1,n+1),n-s))\n",
    "data = pd.read_csv('data.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping columns not needed for this test\n",
    "data = data.drop(columns=['Name', 'AgeClass', \n",
    "                          'Squat4Kg', 'Bench4Kg', 'Deadlift4Kg',\n",
    "                         'Place', 'Tested',\n",
    "                          'Date', 'TotalKg', 'Squat1Kg',\n",
    "                          'Squat2Kg', 'Squat3Kg','Bench1Kg', 'Bench2Kg',\n",
    "                         'Bench3Kg', 'Deadlift1Kg', 'Deadlift2Kg',\n",
    "                          'Deadlift3Kg', 'McCulloch', 'Glossbrenner',\n",
    "                          'WeightClassKg'])\n",
    "\n",
    "data.columns\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General dropna just  to clear those without a WILKS\n",
    "data['Event'].unique()\n",
    "data['Best3BenchKg'].dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dropping athletes who did not compete in complete SBD competitions\n",
    "indexNames = data[data['Event'] == 'S'].index\n",
    "data.drop(indexNames, inplace=True)\n",
    "\n",
    "indexNames = data[data['Event'] == 'B'].index\n",
    "data.drop(indexNames, inplace=True)\n",
    "\n",
    "indexNames = data[data['Event'] == 'D'].index\n",
    "data.drop(indexNames, inplace=True)\n",
    "\n",
    "indexNames = data[data['Event'] == 'SD'].index\n",
    "data.drop(indexNames, inplace=True)\n",
    "\n",
    "indexNames = data[data['Event'] == 'SB'].index\n",
    "data.drop(indexNames, inplace=True)\n",
    "\n",
    "indexNames = data[data['Event'] == 'BD'].index\n",
    "data.drop(indexNames, inplace=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting subsets of the main dataset to run regression depending on competitions.\n",
    "data_s = data[data['Event'] == 'S'] # --> Squat subset\n",
    "data_b = data[data['Event'] == 'B'] # --> Bench subset\n",
    "data_d = data[data['Event'] == 'D'] # --> Deadlift subset\n",
    "data_sd = data[data['Event'] == 'SD'] # --> Squat, Deadlift subset\n",
    "data_sb = data[data['Event'] == 'SB'] # --> Squat, Bench subset\n",
    "data_bd = data[data['Event'] == 'BD'] # --> Bench, Deadlift subset\n",
    "data_sbd = data[data['Event'] == 'SBD'] # --> All lifts subset\n",
    "print('Squats: ' + str(data_s['Sex'].count()))\n",
    "print('Benchpres: ' + str(data_b['Sex'].count()))\n",
    "print('Deadlifts: ' + str(data_d['Sex'].count()))\n",
    "print('Squats and Deadlifts: ' + str(data_sd['Sex'].count()))\n",
    "print('Squats and Benchpresses: ' + str(data_sb['Sex'].count()))\n",
    "print('Benchpresses and Deadlifts: ' + str(data_bd['Sex'].count()))\n",
    "print('All: ' + str(data_sbd['Sex'].count()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchpress Subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_b.drop(['Best3SquatKg', 'Best3DeadliftKg'], axis= 1, inplace= True)\n",
    "data_b.dropna(subset=['Best3BenchKg'], inplace=True)\n",
    "data_b.reset_index(drop=True, inplace=True)\n",
    "data_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert string data to numeric\n",
    "sex = {'M': 1, 'F': 0}\n",
    "# Boolean for equipment\n",
    "equipment = {'Raw': 0, 'Wraps': 1, 'Multi-ply': 1, 'Single-ply': 1, 'Straps': 1}\n",
    "\n",
    "data_b.Sex = [sex[item] for item in data_b.Sex]\n",
    "data_b.Equipment = [equipment[item] for item in data_b.Equipment]\n",
    "data_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalise the data, scaling to values between 0-1\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "data_b[['Sex', 'Age', 'Equipment', 'BodyweightKg',\n",
    "        'Wilks', 'Best3BenchKg']] = scaler.fit_transform(data_b[['Sex', 'Age', 'Equipment', 'BodyweightKg',\n",
    "        'Wilks', 'Best3BenchKg']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So, running 3 different test and training sets.\n",
    "# First for squats, then bench, finally deadlifts,\n",
    "# See the model accuracy for predicting someone's lifts.\n",
    "# Further experiments to see which variables are critical\n",
    "# to accurate prediction. How accurate can we get with age,\n",
    "# sex, weight, and equipment?\n",
    "\n",
    "test_data_b = data_b[[ 'Sex', 'Age', 'BodyweightKg', 'Equipment', 'Wilks']]\n",
    "\n",
    "target_bench_b = data_b[['Best3BenchKg']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare the sets\n",
    "X = test_data_b\n",
    "b = target_bench_b\n",
    "# b = target_bench\n",
    "# d = target_dead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split sets into training and test sets\n",
    "X_train, X_test, b_train, b_test = train_test_split(X, b, test_size=0.1, random_state=3)\n",
    "# X_train, X_test, b_train, b_test = train_test_split(X, b, test_size=0.1, random_state=3)\n",
    "# X_train, X_test, d_train, d_test = train_test_split(X, d, test_size=0.1, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare random forest models, check r2_scores.\n",
    "brfregr = RandomForestRegressor(n_estimators=100, max_depth = 30)\n",
    "# brfregr = RandomForestRegressor(n_estimators=100, max_depth = 30)\n",
    "# drfregr = RandomForestRegressor(n_estimators=100, max_depth = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brfregr.fit(X_train, b_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B_rfr = brfregr.predict(X_test)\n",
    "print(\"R2-score: %.2f\" % r2_score(B_rfr , b_test))\n",
    "print(\"RMSE: %.2f\" % np.sqrt(metrics.mean_squared_error(b_test, B_rfr)))\n",
    "print(\"Std: %.2f\" % b_test.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brfregr.fit(X_train, b_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B_rfr = brfregr.predict(X_test)\n",
    "print(\"R2-score: %.2f\" % r2_score(B_rfr , b_test))\n",
    "print(\"RMSE: %.2f\" % np.sqrt(metrics.mean_squared_error(b_test, B_rfr)))\n",
    "print(\"Std: %.2f\" % b_test.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brfregr.fit(X_train, b_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_rfr = drfregr.predict(X_test)\n",
    "print(\"R2-score: %.2f\" % r2_score(D_rfr , d_test))\n",
    "print(\"RMSE: %.2f\" % np.sqrt(metrics.mean_squared_error(d_test, D_rfr)))\n",
    "print(\"Std: %.2f\" % d_test.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare Lineaar models and check r2_scores\n",
    "S_linreg = LinearRegression()\n",
    "B_linreg = LinearRegression()\n",
    "D_linreg = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S_linreg.fit(X_train, s_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S_lin = S_linreg.predict(X_test)\n",
    "print(\"R2-score: %.2f\" % r2_score(S_lin , s_test))\n",
    "print(\"RMSE: %.2f\" % np.sqrt(metrics.mean_squared_error(s_test, S_lin)))\n",
    "print(\"Std: %.2f\" % s_test.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B_linreg.fit(X_train, b_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B_lin = B_linreg.predict(X_test)\n",
    "print(\"R2-score: %.2f\" % r2_score(B_lin , b_test))\n",
    "print(\"RMSE: %.2f\" % np.sqrt(metrics.mean_squared_error(b_test, B_lin)))\n",
    "print(\"Std: %.2f\" % b_test.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_linreg.fit(X_train, d_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_lin = D_linreg.predict(X_test)\n",
    "print(\"R2-score: %.2f\" % r2_score(D_lin , d_test))\n",
    "print(\"RMSE: %.2f\" % np.sqrt(metrics.mean_squared_error(d_test, D_lin)))\n",
    "print(\"Std: %.2f\" % d_test.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfr_pred = pd.DataFrame(srfregr.predict(X_test))\n",
    "\n",
    "slr_pred = pd.DataFrame(S_linreg.predict(X_test))\n",
    "\n",
    "\n",
    "S_bw = pd.DataFrame(X_test['BodyweightKg'])\n",
    "S_bw = S_bw.reset_index()\n",
    "S_bw = S_bw.drop(columns = 'index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xfit = np.linspace(0, 1)\n",
    "yfit = RandomForestRegressor().fit(S_bw, sfr_pred.values.ravel()).predict(xfit[:, None])\n",
    "zfit = RandomForestRegressor().fit(S_bw, s_test.values.ravel()).predict(xfit[:, None])\n",
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "plt.subplot(1 , 2, 1)\n",
    "plt.scatter(S_bw, s_test, color = 'g', label='Actual Squats', alpha=0.2)\n",
    "plt.plot(xfit, np.sin(zfit), color = 'b', label='Real');\n",
    "plt.plot([0,0.8], [0,0.8], 'k--')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1 , 2, 2)\n",
    "plt.scatter(S_bw, s_test, color = 'g', label='Actual Squats', alpha=0.2)\n",
    "plt.plot(xfit, np.sin(yfit), color = 'r', label='Pred');\n",
    "plt.plot([0,0.8], [0,0.8], 'k--')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xfit = np.linspace(0, 0.8)\n",
    "yfit = RandomForestRegressor().fit(S_bw, sfr_pred.values.ravel()).predict(xfit[:, None])\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "plt.errorbar(xfit, yfit, 0.1, fmt='.g')\n",
    "plt.plot([0,0.8], [0,0.8], 'k--')\n",
    "ax.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xfit = np.linspace(0, 1)\n",
    "yfit = LinearRegression().fit(S_bw, slr_pred).predict(xfit[:, None])\n",
    "zfit = LinearRegression().fit(S_bw, s_test).predict(xfit[:, None])\n",
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "plt.subplot(1 , 2, 1)\n",
    "plt.scatter(S_bw, s_test, color = 'g', label='Actual Squats', alpha=0.2)\n",
    "plt.plot(xfit, np.sin(zfit), color = 'b', label='Real');\n",
    "plt.plot([0,0.8], [0,0.8], 'k--')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1 , 2, 2)\n",
    "plt.scatter(S_bw, s_test, color = 'g', label='Actual Squats', alpha=0.2)\n",
    "plt.plot(xfit, np.sin(yfit), color = 'r', label='Pred');\n",
    "plt.plot([0,0.8], [0,0.8], 'k--')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "ax.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xfit = np.linspace(0, 1)\n",
    "yfit = LinearRegression().fit(S_bw, slr_pred).predict(xfit[:, None])\n",
    "zfit = LinearRegression().fit(S_bw, s_test).predict(xfit[:, None])\n",
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "plt.subplot(1 , 2, 1)\n",
    "plt.scatter(S_bw, s_test, color = 'g', label='Actual Squats', alpha=0.2)\n",
    "plt.plot([0,0.8], [0,1], 'k--')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1 , 2, 2)\n",
    "plt.scatter(S_bw, slr_pred, color = 'purple', label='Predicted Squats', alpha=0.2)\n",
    "plt.plot([0,0.8], [0,1], 'k--')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "ax.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_sizes = [1, 500, 2000, 5000, 7500, 10000, 15000, 19000]\n",
    "\n",
    "train_sizes, train_scores, validation_scores = learning_curve(\n",
    "estimator = LinearRegression(),\n",
    "X = X,\n",
    "y = s, train_sizes = training_sizes,cv = 100,\n",
    "scoring = 'neg_mean_absolute_error')\n",
    "\n",
    "train_scores_mean = -train_scores.mean(axis = 1)*1000\n",
    "validation_scores_mean = -validation_scores.mean(axis = 1)*1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7.5,7.5))\n",
    "plt.plot(train_sizes, train_scores_mean, 'b--', label = 'Training error')\n",
    "plt.plot(train_sizes, validation_scores_mean, 'r--', label = 'Test error')\n",
    "plt.ylabel('MAE*1000', fontsize = 14)\n",
    "plt.xlabel('Training set size', fontsize = 14)\n",
    "plt.title('Learning curves for linear regression', fontsize = 12, y = 1.03)\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.ylim(0, 50)\n",
    "plt.xlim(0, 15000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
